{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/meghanabhange/Arctic-Monkeys-Lyrics-Generator/blob/master/AMLyricsGenerator_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzbizYhP_OcP"
   },
   "source": [
    "#~Arctic Monkey's~ Your Artist Lyrics generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KQm9CETRQQL"
   },
   "source": [
    "# GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rE3ED-za8Qn"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "aSdd7hYJRRtX",
    "outputId": "40095252-ae3f-47a4-99f8-75570162cb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install gpt_2_simple\n",
    "!pip install tensorflow==1.14\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhwTD28VRUVG"
   },
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "\n",
    "gpt2.download_gpt2()  # model is saved into current directory under /models/117M/\n",
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "s9fEeexfa1dd",
    "outputId": "60cfc49d-559a-42cf-a665-fa25e16e371a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Vwfhsmx0zH85fVBg2Rcm239qLhqywRBk\n",
      "To: /content/am_corpus_original.txt\n",
      "100%|██████████| 173k/173k [00:00<00:00, 26.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "\n",
    "def get_files_from_gdrive(url: str, fname: str) -> None:\n",
    "    file_id = url.split(\"/\")[5]\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, fname, quiet=False)\n",
    "\n",
    "\n",
    "get_files_from_gdrive(\n",
    "    \"https://drive.google.com/file/d/1Vwfhsmx0zH85fVBg2Rcm239qLhqywRBk/view?usp=sharing\",\n",
    "    \"am_corpus_original.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "mrCoqCw8RXMt",
    "outputId": "a9dd2338-6111-4c56-b1cb-f334126b8a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint models/124M/model.ckpt\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 42575 tokens\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "gpt2.finetune(\n",
    "    sess, \"am_corpus_original.txt\", steps=1000, save_every=1000, batch_size=100\n",
    ")  # steps is max number of training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gq66nggVRfcf"
   },
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "maxlen = 40\n",
    "N = 500\n",
    "out = gpt2.generate(sess, return_as_list=True, prefix=None, length=N, seed=1)\n",
    "out = \"\".join(out)\n",
    "pp.pprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fasgOaLnRyQL"
   },
   "outputs": [],
   "source": [
    "# !pip install rouge\n",
    "import pprint\n",
    "\n",
    "from rouge import Rouge\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=100, compact=True)\n",
    "N = 50\n",
    "print(\"__OpenAI GPT-2__\")\n",
    "print(\"__ROUGE__\")\n",
    "rouge = Rouge()\n",
    "pp.pprint(f\"Generated Output: {out1}\")\n",
    "scores_aug = rouge.get_scores(out1, text[:N], avg=True)\n",
    "print(\"Scores With Data Aug: \")\n",
    "pp.pprint(scores_aug)\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "pp.pprint(f\"Generated Output: {out2}\")\n",
    "scores_no_aug = rouge.get_scores(out2, text[:N], avg=True)\n",
    "print(\"Scores Without Data Aug: \")\n",
    "pp.pprint(scores_no_aug)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGwTCBDB3C1xoOM20yJkRg",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "AMLyricsGenerator-GPT2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
