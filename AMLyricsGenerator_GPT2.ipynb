{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMLyricsGenerator-GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGwTCBDB3C1xoOM20yJkRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghanabhange/Arctic-Monkeys-Lyrics-Generator/blob/master/AMLyricsGenerator_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzbizYhP_OcP",
        "colab_type": "text"
      },
      "source": [
        "#~Arctic Monkey's~ Your Artist Lyrics generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KQm9CETRQQL",
        "colab_type": "text"
      },
      "source": [
        "# GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rE3ED-za8Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSdd7hYJRRtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "40095252-ae3f-47a4-99f8-75570162cb7b"
      },
      "source": [
        "!pip install gpt_2_simple\n",
        "!pip install tensorflow==1.14\n",
        "!pip install gdown"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhwTD28VRUVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "gpt2.download_gpt2()   # model is saved into current directory under /models/117M/\n",
        "sess = gpt2.start_tf_sess()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9fEeexfa1dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "60cfc49d-559a-42cf-a665-fa25e16e371a"
      },
      "source": [
        "import gdown\n",
        "def get_files_from_gdrive(url: str, fname: str) -> None:\n",
        "    file_id = url.split(\"/\")[5]\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, fname, quiet=False)\n",
        "\n",
        "get_files_from_gdrive(\"https://drive.google.com/file/d/1Vwfhsmx0zH85fVBg2Rcm239qLhqywRBk/view?usp=sharing\" , \"am_corpus_original.txt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Vwfhsmx0zH85fVBg2Rcm239qLhqywRBk\n",
            "To: /content/am_corpus_original.txt\n",
            "100%|██████████| 173k/173k [00:00<00:00, 26.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrCoqCw8RXMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "a9dd2338-6111-4c56-b1cb-f334126b8a67"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "  \n",
        "gpt2.finetune(sess, 'am_corpus_original.txt', steps=1000, save_every = 1000, batch_size= 100)   # steps is max number of training steps\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 42575 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq66nggVRfcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_index = 0\n",
        "maxlen = 40\n",
        "N = 500\n",
        "out = gpt2.generate(sess, return_as_list=True, prefix=None, length=N,seed = 1)\n",
        "out = ''.join(out)\n",
        "pp.pprint(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fasgOaLnRyQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge \n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(width=100, compact=True)\n",
        "N=50\n",
        "print(\"__OpenAI GPT-2__\")\n",
        "print(\"__ROUGE__\")\n",
        "rouge = Rouge()\n",
        "pp.pprint(f\"Generated Output: {out1}\")\n",
        "scores_aug = rouge.get_scores(out1, text[:N],avg=True)\n",
        "print(\"Scores With Data Aug: \")\n",
        "pp.pprint(scores_aug)\n",
        "\n",
        "\n",
        "rouge = Rouge()\n",
        "pp.pprint(f\"Generated Output: {out2}\")\n",
        "scores_no_aug = rouge.get_scores(out2, text[:N],avg=True)\n",
        "print(\"Scores Without Data Aug: \")\n",
        "pp.pprint(scores_no_aug)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}